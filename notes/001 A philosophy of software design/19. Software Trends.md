# Software Trends

## Unit tests

> Tests, particularly unit tests, play an important role in software design
> because they facilitate refactoring. Without a test suite, it's dangerous
> to make major structural changes to a system. There's no easy way to find
> bugs, so it's likely that bugs will go undetected until the new code is
> deployed, where they are much more expensive to find and find. As a result,
> developers avoid refactoring in systems without good test suites; they try
> to minimize the number of code changes for each new feature or bug fix,
> which means that complexity accumulates and design mistakes don't get
> corrected.

## Test-driven development

> Although I am a strong advocate of unit testing, I am not a fan of test-driven
> development. The problem with test driven development is that it focuses
> attention on getting specific features working, rather than finding the best
> design.

> Test-driven development is too incremental: at any point in time, it's
> tempting to just hack in the next feature to make the next test pass. There's
> no obvious time to do design, so it's easy to end up with a mess.
>
> As mentioned in Section 19.2, the units of development should be abstractions,
> not features.

> One place where it makes sense to write the unit test first is when fixing
> bugs. Before fixing a bug, write a unit test that fails because of the bug.
> (...) If you fix the bug before writing the test, it's possible that the new
> unit test doesn't actually trigger the bug, in which case it won't tell you
> whether you really fixed the problem.

## Design patterns

> Design patterns represent an alternative to design: rather than designing a
> new mechanism from scratch, just apply a well-known design pattern. For the
> most part, this is good: design patterns arose because they solve common
> problems, and because they are generally agreed to provide clean solutions.

## Getters and setters

> One of the risks of establishing a design pattern is that developers assume
> the pattern is good and try to use it as much as possible. This had led to
> overusage of getters and setters in Java.

Is this related in any way to the fact that Java does not offer the `const`
modifier? Is Java's `final` enough to give up getters?